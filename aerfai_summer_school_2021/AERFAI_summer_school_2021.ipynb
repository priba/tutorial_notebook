{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AERFAI_summer_school_2021.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priba/tutorial_notebook/blob/main/aerfai_summer_school_2021/AERFAI_summer_school_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd0__tX7I7Ji"
      },
      "source": [
        "# Graph Neural Networks for Pattern Recognition\n",
        "## AERFAI - Online Summer School on Pattern Recognition and Machine Learning\n",
        "\n",
        "[![View on Github](https://img.shields.io/static/v1.svg?logo=github&label=Repo&message=View%20On%20Github&color=lightgrey)](https://github.com/priba/tutorial_notebook/blob/main/aerfai_summer_school_2021/AERFAI_summer_school_2021.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "Graph Neural Networks (GNNs) have recently gained increasing popularity due to its novel uses in different domains such as Computer Vision, Natural Language Processing, Chemistry, Social Networks or Knowledge Graphs. In this tutorial, we will cover the basic usage of GNN for the problem of node or graph classification. In particular, we will build a GNN from scratch to understand the explained notation and concepts. Later, we will use the provided implementations of several GNN to check the difference in performance.\n",
        "\n",
        "We will use [PyTorch](https://pytorch.org/) as our Deep Learning framework and the [Deep Graph Library (DGL)](https://www.dgl.ai/) as our GNN library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9o8d3mqWpYvb"
      },
      "source": [
        "## Prepare environment\n",
        "\n",
        "Let's start preparing the environment we will use all over the session. First we will change the runtime to work on GPUs and later, we will install all the required libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCXuzl_kNMfe"
      },
      "source": [
        "### Change runtime of notebook to GPU\n",
        "\n",
        "\n",
        "```\n",
        "  Select Runtime -> Change Runtime type -> select runtime python 3 and hardward accelerator GPU\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wss6c9JtNP9g"
      },
      "source": [
        "### Install requirements\n",
        "\n",
        "The basic libraries that will be used are:\n",
        "\n",
        "*   [Network](https://networkx.github.io/)\n",
        "*   [Pytorch](https://pytorch.org/)\n",
        "*   [DGL](https://www.dgl.ai/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-nm23YSArxH"
      },
      "source": [
        "!pip3 install torch\n",
        "!pip3 install dgl-cu110"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFoB_xLWjdTc"
      },
      "source": [
        "## Get the Data\n",
        "\n",
        "The DGL provides several classes for reading graphs!\n",
        "\n",
        "Check:  https://docs.dgl.ai/api/python/dgl.data.html\n",
        "\n",
        "In the following sections we will see 3 examples, 2 for graph classification and 1 for node classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_bzijh9jtBe"
      },
      "source": [
        "### Mini Graph Classification Dataset (MiniGCDataset)\n",
        "\n",
        "This dataset is synthetic and we should define de number and size of the graphs for each set (train, validation and test).\n",
        "\n",
        "*   class 0 : cycle graph\n",
        "*   class 1 : star graph\n",
        "*   class 2 : wheel graph\n",
        "*   class 3 : lollipop graph\n",
        "*   class 4 : hypercube graph\n",
        "*   class 5 : grid graph\n",
        "*   class 6 : clique graph\n",
        "*   class 7 : circular ladder graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSiiF2-68YKf"
      },
      "source": [
        "import dgl\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "dgl.backend = 'pytorch'\n",
        "\n",
        "dataset = dgl.data.MiniGCDataset(100, 23, 50)\n",
        "# Transfer NetworkX graph with the corresponding attributes\n",
        "g, label = dataset[50]\n",
        "\n",
        "# Data structure\n",
        "print(g)\n",
        "\n",
        "# Node Information (empty in the case of MiniGCDataset)\n",
        "print(g.ndata)\n",
        "\n",
        "# Edge Information (empty in the case of simple graphs such as Letters)\n",
        "print(g.edata)\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots()\n",
        "G = g.to_networkx()\n",
        "nx.draw(G, ax=ax, pos=nx.circular_layout(G))\n",
        "ax.set_title('Class: {:d}'.format(label))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1kSqi2Kkdsh"
      },
      "source": [
        "### Graph kernel dataset\n",
        "\n",
        "It allows loading the data from: ENZYMES, DD, COLLAB and MUTAG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf6ZyoCIkAn-"
      },
      "source": [
        "dataset = dgl.data.TUDataset('MUTAG')\n",
        "# Transfer NetworkX graph with the corresponding attributes\n",
        "g, label = dataset[50]\n",
        "\n",
        "# Data structure\n",
        "print(g)\n",
        "\n",
        "# Node Information (empty in the case of MiniGCDataset)\n",
        "print(g.ndata)\n",
        "\n",
        "# Edge Information (empty in the case of simple graphs such as Letters)\n",
        "print(g.edata)\n",
        "\n",
        "# Label\n",
        "print(label)\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots()\n",
        "G = g.to_networkx()\n",
        "nx.draw(G, ax=ax, pos=nx.circular_layout(G))\n",
        "ax.set_title('Class: {:d}'.format(label.item()))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQodjJkQlB4-"
      },
      "source": [
        "### Cora Graph Dataset\n",
        "\n",
        "Is a citation network graph.\n",
        "\n",
        "Nodes mean paper and edges mean citation relationships. Each node has a predefined feature with 1433 dimensions. The dataset is designed for the node classification task. The task is to predict the category of certain paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AORY5wwrlCHW"
      },
      "source": [
        "dataset = dgl.data.CoraGraphDataset()\n",
        "\n",
        "# Transfer NetworkX graph with the corresponding attributes\n",
        "g = dataset[0]\n",
        "\n",
        "# Data structure\n",
        "print(g)\n",
        "\n",
        "# Node Information (empty in the case of MiniGCDataset)\n",
        "print(g.ndata)\n",
        "\n",
        "# Edge Information (empty in the case of simple graphs such as Letters)\n",
        "print(g.edata)\n",
        "\n",
        "# Node classification dataset divides the nodes into training, validation and test sets\n",
        "print(g.ndata['train_mask'])\n",
        "print(g.ndata['val_mask'])\n",
        "print(g.ndata['test_mask'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjJf_8AMm-Yv"
      },
      "source": [
        "### To Define New Dataset Class\n",
        "Pytorch provides an abstract class representig a dataset, ```torch.utils.data.Dataset```. We need to override two methods:\n",
        "\n",
        "*   ```__len__``` so that ```len(dataset)``` returns the size of the dataset.\n",
        "*   ```__getitem__``` to support the indexing such that ```dataset[i]``` can be used to get i-th sample\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FWDCyjjPXl9"
      },
      "source": [
        "## Prepare DataLoader\n",
        "\n",
        "```torch.utils.data.DataLoader``` is an iterator which provides:\n",
        "\n",
        "\n",
        "*   Data batching\n",
        "*   Shuffling the data\n",
        "*   Parallel data loading\n",
        "\n",
        "In our specific case, we need to deal with graphs of many sizes. Hence, we define a new collate function makin guse of the method ```dgl.batch```.\n",
        "\n",
        "In this example we will work with the MiniGCDataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea8B1D8z-TlB"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def collate(samples):\n",
        "    # The input `samples` is a list of pairs\n",
        "    #  (graph, label).\n",
        "    graphs, labels = map(list, zip(*samples))\n",
        "    batched_graph = dgl.batch(graphs)\n",
        "    return batched_graph, torch.tensor(labels)\n",
        "\n",
        "# Define the corresponding subsets for train, validation and test.\n",
        "trainset = dgl.data.MiniGCDataset(1000, 23, 50)\n",
        "validset = dgl.data.MiniGCDataset(100, 23, 100)\n",
        "testset = dgl.data.MiniGCDataset(500, 23, 100)\n",
        "\n",
        "# Define the three dataloaders. Train data will be shuffled at each epoch\n",
        "train_loader = DataLoader(trainset, batch_size=32, shuffle=True,\n",
        "                         collate_fn=collate)\n",
        "valid_loader = DataLoader(validset, batch_size=32, collate_fn=collate)\n",
        "test_loader = DataLoader(testset, batch_size=32, collate_fn=collate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cRRfYBqnHJA"
      },
      "source": [
        "## Define GNN model\n",
        "\n",
        "We have two options.\n",
        "\n",
        "*   To define our own GNN layers (see next section)\n",
        "*   To use predefined GNN layers (skip to NN Modules)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-9eZEvJPb_r"
      },
      "source": [
        "### Define our own Model\n",
        "\n",
        "To define a Graph Convolution, three functions have to be defined:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Message: Decide which information is sent by a node\n",
        "*   Reduce: Combine the messages and the current data\n",
        "*   NodeApply: Update the node features that are recieved from the reduce function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02lS2sM6Pa_e"
      },
      "source": [
        "import dgl.function as fn\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Sends a message of node feature h.\n",
        "msg = fn.copy_src(src='h', out='m')\n",
        "def message_func(edges):\n",
        "    return {'m': edges.src['h']}\n",
        "\n",
        "def reduce(nodes):\n",
        "  \"\"\"Take an average over all neighbor node features hu and use it to\n",
        "  overwrite the original node feature.\"\"\"\n",
        "  accum = torch.sum(nodes.mailbox['m'], 1)\n",
        "  return {'m': accum}\n",
        "\n",
        "class NodeApplyModule(nn.Module):\n",
        "  \"\"\"Update the node feature hv with ReLU(Whv+b).\"\"\"\n",
        "  def __init__(self, in_feats, out_feats, activation):\n",
        "    super(NodeApplyModule, self).__init__()\n",
        "    self.linear = nn.Linear(in_feats, out_feats)\n",
        "    self.activation = activation\n",
        "\n",
        "  def forward(self, node):\n",
        "    h = torch.cat([node.data['h'], node.data['m']],1)\n",
        "    h = self.linear(h)\n",
        "    h = self.activation(h)\n",
        "    return {'h' : h}  \n",
        "  \n",
        "class GCN(nn.Module):\n",
        "  \"\"\"Define a GCN layer\"\"\"\n",
        "  def __init__(self, in_feats, out_feats, activation):\n",
        "    super(GCN, self).__init__()\n",
        "    self.apply_mod = NodeApplyModule(2*in_feats, out_feats, activation)\n",
        "    \n",
        "  def forward(self, g, feature):\n",
        "    # Initialize the node features with h.\n",
        "    g.ndata['h'] = feature\n",
        "    g.update_all(msg, reduce)\n",
        "    g.apply_nodes(func=self.apply_mod)\n",
        "    return g.ndata.pop('h')\n",
        "  \n",
        "class Net(nn.Module):\n",
        "  def __init__(self, in_dim, hidden_dim, n_classes):\n",
        "    super(Net, self).__init__()\n",
        "    self.layers = nn.ModuleList([\n",
        "        GCN(in_dim, hidden_dim, F.relu),\n",
        "        GCN(hidden_dim, hidden_dim, F.relu)])\n",
        "    self.classify = nn.Linear(hidden_dim, n_classes)\n",
        "    \n",
        "  def forward(self, g):\n",
        "    # For undirected graphs, in_degree is the same as\n",
        "    # out_degree.\n",
        "    h = g.in_degrees().view(-1, 1).float()\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "      h = h.cuda() \n",
        "    for conv in self.layers:\n",
        "      h = conv(g, h)\n",
        "    g.ndata['h'] = h\n",
        "    hg = dgl.mean_nodes(g, 'h')\n",
        "    return self.classify(hg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXZ20gTpY3lK"
      },
      "source": [
        "### NN Modules\n",
        "\n",
        "Several GNN layers are provided by default as [NN Modules](https://docs.dgl.ai/api/python/nn.pytorch.html#graphconv).\n",
        "\n",
        "**Choose the network to use, either with NN Modules or defining it as it has been shown before.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc5FnY8gY1PJ"
      },
      "source": [
        "from dgl.nn.pytorch import GraphConv\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self, in_dim, hidden_dim, n_classes):\n",
        "    super(Net, self).__init__()\n",
        "    self.layers = nn.ModuleList([\n",
        "        GraphConv(in_dim, hidden_dim, activation=F.relu),\n",
        "        GraphConv(hidden_dim, hidden_dim, activation=F.relu)])\n",
        "    self.classify = nn.Linear(hidden_dim, n_classes)\n",
        "    \n",
        "  def forward(self, g):\n",
        "    # Use node degree as the initial node feature. For undirected graphs, the in-degree\n",
        "    # is the same as the out_degree.\n",
        "    h = g.in_degrees().view(-1, 1).float()\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "      h = h.cuda() \n",
        "      \n",
        "    for conv in self.layers:\n",
        "      h = conv(g, h)\n",
        "      \n",
        "    g.ndata['h'] = h\n",
        "    hg = dgl.mean_nodes(g, 'h')\n",
        "    return self.classify(hg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pPWJfxYUyXg"
      },
      "source": [
        "## Training setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inHmWtgwUxy-"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "model = Net(1, 256, trainset.num_classes)\n",
        "if torch.cuda.is_available():\n",
        "  model = model.cuda()\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "model.train()\n",
        "\n",
        "epoch_losses = []\n",
        "for epoch in range(80):\n",
        "  epoch_loss = 0\n",
        "  for iter, (bg, label) in enumerate(train_loader):\n",
        "    if torch.cuda.is_available():\n",
        "      label = label.cuda()\n",
        "      bg = bg.to(label.device)\n",
        "    prediction = model(bg)\n",
        "    loss = loss_func(prediction, label)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.detach().item()\n",
        "  epoch_loss /= (iter + 1)\n",
        "  print('Epoch {}, loss {:.4f}'.format(epoch, epoch_loss))\n",
        "  epoch_losses.append(epoch_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkxZZXdT9Kq_"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-peNt4q9861W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82cec51d-65e1-46fe-90d5-03253954563c"
      },
      "source": [
        "def accuracy(output, target):\n",
        "  \"\"\"Accuacy given a logit vector output and a target class\n",
        "  \"\"\"\n",
        "  _, pred = output.topk(1)\n",
        "  pred = pred.squeeze()\n",
        "  correct = pred == target\n",
        "  correct = correct.float()\n",
        "  return correct.sum() * 100.0 / correct.shape[0]\n",
        "\n",
        "\n",
        "model.eval()\n",
        "acc = 0\n",
        "with torch.no_grad():\n",
        "  for iter, (bg, label) in enumerate(test_loader):\n",
        "    if torch.cuda.is_available():\n",
        "        label = label.cuda()\n",
        "        bg = bg.to(label.device)\n",
        "    prediction = model(bg)\n",
        "    acc += accuracy(prediction, label) * label.shape[0]\n",
        "acc = acc/len(testset)\n",
        "\n",
        "print('Test accuracy {:.4f}'.format(acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy 87.6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-R1ZDmqkdN0"
      },
      "source": [
        "## Plot results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_Lkp4sqeg8T"
      },
      "source": [
        "from random import randrange\n",
        "import matplotlib.pyplot as plt\n",
        "for i in range(10):\n",
        "  index = randrange(len(testset))\n",
        "  g, label = testset[index]\n",
        "  pred = model(g.to('cuda'))\n",
        "  _, pred = pred.topk(1)\n",
        "  G = g.to_networkx()\n",
        "  plt.figure(i)\n",
        "  nx.draw(G, pos=nx.circular_layout(G), arrows=False)\n",
        "  plt.show()\n",
        "  print('Label {}; Prediction {}'.format(label, pred.item()))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}